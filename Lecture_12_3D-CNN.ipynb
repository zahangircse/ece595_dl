{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/zahangir/.local/lib/python2.7/site-packages/requests/__init__.py:83: RequestsDependencyWarning: Old version of cryptography ([1, 2, 3]) may cause slowdown.\n",
      "  warnings.warn(warning, RequestsDependencyWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Conv3D, MaxPool3D, Flatten, Dense\n",
    "from keras.layers import Dropout, Input, BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta\n",
    "import plotly.graph_objs as go\n",
    "from matplotlib.pyplot import cm\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import keras\n",
    "import h5py\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read 3D MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train shape: ', (10000, 4096))\n",
      "('y_train shape: ', (10000,))\n",
      "('x_test shape:  ', (2000, 4096))\n",
      "('y_test shape:  ', (2000,))\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('full_dataset_vectors.h5', 'r') as dataset:\n",
    "    x_train = dataset[\"X_train\"][:]\n",
    "    x_test = dataset[\"X_test\"][:]\n",
    "    y_train = dataset[\"y_train\"][:]\n",
    "    y_test = dataset[\"y_test\"][:]\n",
    "\n",
    "    \n",
    "print (\"x_train shape: \", x_train.shape)\n",
    "print (\"y_train shape: \", y_train.shape)\n",
    "\n",
    "print (\"x_test shape:  \", x_test.shape)\n",
    "print (\"y_test shape:  \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train shape: ', (10000, 16, 16, 16, 3))\n",
      "('y_train shape: ', (10000, 10))\n",
      "('x_test shape:  ', (2000, 16, 16, 16, 3))\n",
      "('y_test shape:  ', (2000, 10))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Introduce the channel dimention in the input dataset \n",
    "xtrain = np.ndarray((x_train.shape[0], 4096, 3))\n",
    "xtest = np.ndarray((x_test.shape[0], 4096, 3))\n",
    "\n",
    "## iterate in train and test, add the rgb dimention \n",
    "def add_rgb_dimention(array):\n",
    "    scaler_map = cm.ScalarMappable(cmap=\"Oranges\")\n",
    "    array = scaler_map.to_rgba(array)[:, : -1]\n",
    "    return array\n",
    "for i in range(x_train.shape[0]):\n",
    "    xtrain[i] = add_rgb_dimention(x_train[i])\n",
    "for i in range(x_test.shape[0]):\n",
    "    xtest[i] = add_rgb_dimention(x_test[i])\n",
    "\n",
    "## convert to 1 + 4D space (1st argument represents number of rows in the dataset)\n",
    "xtrain = xtrain.reshape(x_train.shape[0], 16, 16, 16, 3)\n",
    "xtest = xtest.reshape(x_test.shape[0], 16, 16, 16, 3)\n",
    "\n",
    "## convert target variable into one-hot\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "print (\"x_train shape: \", xtrain.shape)\n",
    "print (\"y_train shape: \", y_train.shape)\n",
    "\n",
    "print (\"x_test shape:  \", xtest.shape)\n",
    "print (\"y_test shape:  \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct an 3D CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 16, 16, 16, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 14, 14, 14, 8)     656       \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 12, 12, 12, 16)    3472      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 6, 6, 6, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 4, 4, 4, 32)       13856     \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 2, 2, 2, 64)       55360     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 1, 1, 1, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 1, 1, 64)       256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              133120    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,260,938\n",
      "Trainable params: 1,260,810\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## input layer\n",
    "input_layer = Input((16, 16, 16, 3))\n",
    "\n",
    "## convolutional layers\n",
    "conv_layer1 = Conv3D(filters=8, kernel_size=(3, 3, 3), activation='relu')(input_layer)\n",
    "conv_layer2 = Conv3D(filters=16, kernel_size=(3, 3, 3), activation='relu')(conv_layer1)\n",
    "\n",
    "## add max pooling to obtain the most imformatic features\n",
    "pooling_layer1 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer2)\n",
    "\n",
    "conv_layer3 = Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu')(pooling_layer1)\n",
    "conv_layer4 = Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu')(conv_layer3)\n",
    "pooling_layer2 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer4)\n",
    "\n",
    "## perform batch normalization on the convolution outputs before feeding it to MLP architecture\n",
    "pooling_layer2 = BatchNormalization()(pooling_layer2)\n",
    "flatten_layer = Flatten()(pooling_layer2)\n",
    "\n",
    "## create an MLP architecture with dense layers : 4096 -> 512 -> 10\n",
    "## add dropouts to avoid overfitting / perform regularization\n",
    "dense_layer1 = Dense(units=2048, activation='relu')(flatten_layer)\n",
    "dense_layer1 = Dropout(0.4)(dense_layer1)\n",
    "dense_layer2 = Dense(units=512, activation='relu')(dense_layer1)\n",
    "dense_layer2 = Dropout(0.4)(dense_layer2)\n",
    "output_layer = Dense(units=10, activation='softmax')(dense_layer2)\n",
    "\n",
    "## define the model with input layer and output layer\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model and start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 172s 21ms/step - loss: 2.1894 - acc: 0.2233 - val_loss: 1.9893 - val_acc: 0.2990\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 169s 21ms/step - loss: 1.7918 - acc: 0.3880 - val_loss: 1.6951 - val_acc: 0.4085\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 1.4726 - acc: 0.5034 - val_loss: 1.7925 - val_acc: 0.3770\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 1.2944 - acc: 0.5533 - val_loss: 1.7000 - val_acc: 0.4490\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 1.1900 - acc: 0.5895 - val_loss: 1.2128 - val_acc: 0.5780\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 1.1001 - acc: 0.6236 - val_loss: 1.3454 - val_acc: 0.5415\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 1.0313 - acc: 0.6456 - val_loss: 1.1496 - val_acc: 0.5970\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.9804 - acc: 0.6611 - val_loss: 1.2335 - val_acc: 0.5750\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.9284 - acc: 0.6764 - val_loss: 1.6642 - val_acc: 0.5115\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.8855 - acc: 0.6986 - val_loss: 1.0636 - val_acc: 0.6235\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.8341 - acc: 0.7164 - val_loss: 1.8964 - val_acc: 0.4675\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.7998 - acc: 0.7244 - val_loss: 1.1823 - val_acc: 0.6045\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.7570 - acc: 0.7415 - val_loss: 1.1175 - val_acc: 0.6285\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.7204 - acc: 0.7537 - val_loss: 1.2888 - val_acc: 0.5990\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.6823 - acc: 0.7664 - val_loss: 1.0755 - val_acc: 0.6340\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.6489 - acc: 0.7770 - val_loss: 1.1555 - val_acc: 0.6335\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.6255 - acc: 0.7905 - val_loss: 1.2326 - val_acc: 0.6195\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.5918 - acc: 0.7983 - val_loss: 1.4076 - val_acc: 0.5870\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.5537 - acc: 0.8103 - val_loss: 1.1589 - val_acc: 0.6380\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.5323 - acc: 0.8245 - val_loss: 1.1692 - val_acc: 0.6410\n",
      "Epoch 21/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.4993 - acc: 0.8296 - val_loss: 1.4964 - val_acc: 0.5995\n",
      "Epoch 22/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.4702 - acc: 0.8451 - val_loss: 1.2153 - val_acc: 0.6355\n",
      "Epoch 23/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.4369 - acc: 0.8574 - val_loss: 1.3596 - val_acc: 0.6390\n",
      "Epoch 24/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.4085 - acc: 0.8688 - val_loss: 1.2793 - val_acc: 0.6405\n",
      "Epoch 25/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.3901 - acc: 0.8690 - val_loss: 1.4125 - val_acc: 0.6180\n",
      "Epoch 26/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.3576 - acc: 0.8834 - val_loss: 1.3585 - val_acc: 0.6415\n",
      "Epoch 27/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.3375 - acc: 0.8888 - val_loss: 1.3467 - val_acc: 0.6370\n",
      "Epoch 28/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.3084 - acc: 0.9011 - val_loss: 1.4286 - val_acc: 0.6390\n",
      "Epoch 29/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.2867 - acc: 0.9110 - val_loss: 1.4863 - val_acc: 0.6185\n",
      "Epoch 30/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.2637 - acc: 0.9179 - val_loss: 1.4572 - val_acc: 0.6345\n",
      "Epoch 31/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.2453 - acc: 0.9251 - val_loss: 1.4797 - val_acc: 0.6400\n",
      "Epoch 32/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.2262 - acc: 0.9295 - val_loss: 1.4611 - val_acc: 0.6465\n",
      "Epoch 33/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.2094 - acc: 0.9389 - val_loss: 1.6734 - val_acc: 0.6380\n",
      "Epoch 34/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.1927 - acc: 0.9429 - val_loss: 1.6399 - val_acc: 0.6295\n",
      "Epoch 35/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.1758 - acc: 0.9484 - val_loss: 1.5920 - val_acc: 0.6460\n",
      "Epoch 36/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.1577 - acc: 0.9571 - val_loss: 1.7981 - val_acc: 0.6220\n",
      "Epoch 37/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.1399 - acc: 0.9619 - val_loss: 1.7975 - val_acc: 0.6285\n",
      "Epoch 38/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.1274 - acc: 0.9664 - val_loss: 2.1576 - val_acc: 0.6095\n",
      "Epoch 39/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.1219 - acc: 0.9661 - val_loss: 2.1552 - val_acc: 0.6080\n",
      "Epoch 40/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.1105 - acc: 0.9704 - val_loss: 1.8345 - val_acc: 0.6300\n",
      "Epoch 41/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.1090 - acc: 0.9701 - val_loss: 2.0289 - val_acc: 0.6135\n",
      "Epoch 42/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.0912 - acc: 0.9775 - val_loss: 1.8819 - val_acc: 0.6345\n",
      "Epoch 43/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.0836 - acc: 0.9786 - val_loss: 2.0917 - val_acc: 0.6245\n",
      "Epoch 44/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.0712 - acc: 0.9848 - val_loss: 2.0889 - val_acc: 0.6255\n",
      "Epoch 45/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.0708 - acc: 0.9816 - val_loss: 1.9384 - val_acc: 0.6410\n",
      "Epoch 46/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.0645 - acc: 0.9846 - val_loss: 2.0665 - val_acc: 0.6320\n",
      "Epoch 47/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.0636 - acc: 0.9845 - val_loss: 2.3830 - val_acc: 0.6180\n",
      "Epoch 48/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.0534 - acc: 0.9889 - val_loss: 2.1660 - val_acc: 0.6340\n",
      "Epoch 49/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.0530 - acc: 0.9873 - val_loss: 2.1765 - val_acc: 0.6425\n",
      "Epoch 50/50\n",
      "8000/8000 [==============================] - 168s 21ms/step - loss: 0.0467 - acc: 0.9903 - val_loss: 2.4770 - val_acc: 0.6260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feacd4e3a50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=categorical_crossentropy, optimizer=Adadelta(lr=0.1), metrics=['acc'])\n",
    "model.fit(x=xtrain, y=y_train, batch_size=128, epochs=50, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test loss:', 2.4064021339416506)\n",
      "('Test accuracy:', 0.623)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(xtest, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the labels from prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(xtest)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
