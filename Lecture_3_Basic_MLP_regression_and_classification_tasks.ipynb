{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of MLP\n",
    "- Objective: create vanilla neural networks (i.e., Multilayer perceptrons) for simple regression/classification tasks with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Structures\n",
    "- Each MLP model is consisted of one input layer, several hidden layers, and one output layer\n",
    "- Number of neurons in each layer is not limited\n",
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net.jpeg\" style=\"width: 300px\"/>\n",
    "<br>\n",
    "<center>**MLP with one hidden layer**</center>\n",
    "- Number of input neurons: 3\n",
    "- Number of hidden neurons: 4\n",
    "- Number of output neurons: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" style=\"width: 500px\"/>\n",
    "<br>\n",
    "<center>**MLP with two hidden layers**</center>\n",
    "- Number of input neurons: 3\n",
    "- Number of hidden neurons: (4, 4)\n",
    "- Number of output neurons: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP for Regression tasks\n",
    "- When the target (**y**) is continuous (real)\n",
    "- For loss function and evaluation metric, mean squared error (MSE) is commonly used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/zahangir/.local/lib/python2.7/site-packages/requests/__init__.py:83: RequestsDependencyWarning: Old version of cryptography ([1, 2, 3]) may cause slowdown.\n",
      "  warnings.warn(warning, RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "- Boston housing dataset has total 506 data instances (404 training & 102 test)\n",
    "- 13 attributes (features) to predict \"the median values of the houses at a location\"\n",
    "- Doc: https://keras.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(102, 13)\n",
      "(404,)\n",
      "(102,)\n",
      "Y_test values:\n",
      "[ 7.2 18.8 19.  27.  22.2 24.5 31.2 22.9 20.5 23.2 18.6 14.5 17.8 50.\n",
      " 20.8 24.3 24.2 19.8 19.1 22.7 12.  10.2 20.  18.5 20.9 23.  27.5 30.1\n",
      "  9.5 22.  21.2 14.1 33.1 23.4 20.1  7.4 15.4 23.8 20.1 24.5 33.  28.4\n",
      " 14.1 46.7 32.5 29.6 28.4 19.8 20.2 25.  35.4 20.3  9.7 14.5 34.9 26.6\n",
      "  7.2 50.  32.4 21.6 29.8 13.1 27.5 21.2 23.1 21.9 13.  23.2  8.1  5.6\n",
      " 21.7 29.6 19.6  7.  26.4 18.9 20.9 28.1 35.4 10.2 24.3 43.1 17.6 15.4\n",
      " 16.2 27.1 21.4 21.5 22.4 25.  16.6 18.6 22.  42.8 35.1 21.5 36.  21.9\n",
      " 24.1 50.  26.7 25. ]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(\"Y_test values:\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating a model\n",
    "- Keras model object can be created with Sequential class\n",
    "- At the outset, the model is empty per se. It is completed by **'adding'** additional layers and compilation\n",
    "- Doc: https://keras.io/models/sequential/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 371\n",
      "Trainable params: 371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "model = Sequential()\n",
    "\n",
    "# Keras model with two hidden layer with 10 neurons each \n",
    "model.add(Dense(10, input_shape = (13,)))    # Input layer => input_shape should be explicitly designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))                          # Output layer => output dimension = 1 since it is regression problem\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 622\n",
      "Trainable params: 622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# This is equivalent to the above code block\n",
    "model.add(Dense(10, input_shape = (13,), activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation = 'sigmoid'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Model compile\n",
    "- Keras model should be \"compiled\" prior to training\n",
    "- Types of loss (function) and optimizer should be designated\n",
    "    - Doc (optimizers): https://keras.io/optimizers/\n",
    "    - Doc (losses): https://keras.io/losses/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer\n",
    "model.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mse'])    # for regression problems, mean squared error (MSE) is often employed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training\n",
    "- Training the model with training data provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the parameters:\n",
    "- Batch size: 50\n",
    "- Number of Epochs: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "404/404 [==============================] - 5s 13ms/step - loss: 401.8281 - mean_squared_error: 401.8281\n",
      "Epoch 2/100\n",
      "404/404 [==============================] - 0s 100us/step - loss: 108.0661 - mean_squared_error: 108.0661\n",
      "Epoch 3/100\n",
      "404/404 [==============================] - 0s 96us/step - loss: 86.2543 - mean_squared_error: 86.2543\n",
      "Epoch 4/100\n",
      "404/404 [==============================] - 0s 87us/step - loss: 84.7721 - mean_squared_error: 84.7721\n",
      "Epoch 5/100\n",
      "404/404 [==============================] - 0s 100us/step - loss: 84.7273 - mean_squared_error: 84.7273\n",
      "Epoch 6/100\n",
      "404/404 [==============================] - 0s 91us/step - loss: 84.8906 - mean_squared_error: 84.8906\n",
      "Epoch 7/100\n",
      "404/404 [==============================] - 0s 92us/step - loss: 85.1110 - mean_squared_error: 85.1110\n",
      "Epoch 8/100\n",
      "404/404 [==============================] - 0s 103us/step - loss: 85.1466 - mean_squared_error: 85.1466\n",
      "Epoch 9/100\n",
      "404/404 [==============================] - ETA: 0s - loss: 127.0496 - mean_squared_error: 127.04 - 0s 88us/step - loss: 85.0746 - mean_squared_error: 85.0746\n",
      "Epoch 10/100\n",
      "404/404 [==============================] - 0s 91us/step - loss: 86.4392 - mean_squared_error: 86.4392\n",
      "Epoch 11/100\n",
      "404/404 [==============================] - 0s 95us/step - loss: 84.8958 - mean_squared_error: 84.8958\n",
      "Epoch 12/100\n",
      "404/404 [==============================] - 0s 99us/step - loss: 84.9458 - mean_squared_error: 84.9458\n",
      "Epoch 13/100\n",
      "404/404 [==============================] - 0s 101us/step - loss: 84.8554 - mean_squared_error: 84.8554\n",
      "Epoch 14/100\n",
      "404/404 [==============================] - 0s 94us/step - loss: 84.9553 - mean_squared_error: 84.9553\n",
      "Epoch 15/100\n",
      "404/404 [==============================] - 0s 93us/step - loss: 84.9743 - mean_squared_error: 84.9743\n",
      "Epoch 16/100\n",
      "404/404 [==============================] - 0s 90us/step - loss: 84.9417 - mean_squared_error: 84.9417\n",
      "Epoch 17/100\n",
      "404/404 [==============================] - 0s 99us/step - loss: 84.8692 - mean_squared_error: 84.8692\n",
      "Epoch 18/100\n",
      "404/404 [==============================] - 0s 92us/step - loss: 85.3138 - mean_squared_error: 85.3138\n",
      "Epoch 19/100\n",
      "404/404 [==============================] - 0s 89us/step - loss: 85.1170 - mean_squared_error: 85.1170\n",
      "Epoch 20/100\n",
      "404/404 [==============================] - 0s 99us/step - loss: 84.6867 - mean_squared_error: 84.6867\n",
      "Epoch 21/100\n",
      "404/404 [==============================] - 0s 107us/step - loss: 85.1506 - mean_squared_error: 85.1506\n",
      "Epoch 22/100\n",
      "404/404 [==============================] - 0s 108us/step - loss: 84.6875 - mean_squared_error: 84.6875\n",
      "Epoch 23/100\n",
      "404/404 [==============================] - 0s 103us/step - loss: 84.9881 - mean_squared_error: 84.9881\n",
      "Epoch 24/100\n",
      "404/404 [==============================] - 0s 92us/step - loss: 84.9360 - mean_squared_error: 84.9360\n",
      "Epoch 25/100\n",
      "404/404 [==============================] - 0s 93us/step - loss: 84.9158 - mean_squared_error: 84.9158\n",
      "Epoch 26/100\n",
      "404/404 [==============================] - 0s 90us/step - loss: 84.8269 - mean_squared_error: 84.8269\n",
      "Epoch 27/100\n",
      "404/404 [==============================] - 0s 87us/step - loss: 85.0494 - mean_squared_error: 85.0494\n",
      "Epoch 28/100\n",
      "404/404 [==============================] - ETA: 0s - loss: 88.2746 - mean_squared_error: 88.27 - 0s 109us/step - loss: 84.9607 - mean_squared_error: 84.9607\n",
      "Epoch 29/100\n",
      "404/404 [==============================] - 0s 99us/step - loss: 85.0749 - mean_squared_error: 85.0749\n",
      "Epoch 30/100\n",
      "404/404 [==============================] - 0s 96us/step - loss: 84.9585 - mean_squared_error: 84.9585\n",
      "Epoch 31/100\n",
      "404/404 [==============================] - 0s 90us/step - loss: 85.3405 - mean_squared_error: 85.3405\n",
      "Epoch 32/100\n",
      "404/404 [==============================] - 0s 96us/step - loss: 84.7663 - mean_squared_error: 84.7663\n",
      "Epoch 33/100\n",
      "404/404 [==============================] - 0s 104us/step - loss: 86.0241 - mean_squared_error: 86.0241\n",
      "Epoch 34/100\n",
      "404/404 [==============================] - 0s 103us/step - loss: 85.6537 - mean_squared_error: 85.6537\n",
      "Epoch 35/100\n",
      "404/404 [==============================] - 0s 93us/step - loss: 84.9614 - mean_squared_error: 84.9614\n",
      "Epoch 36/100\n",
      "404/404 [==============================] - 0s 97us/step - loss: 84.8704 - mean_squared_error: 84.8704\n",
      "Epoch 37/100\n",
      "404/404 [==============================] - 0s 93us/step - loss: 85.0643 - mean_squared_error: 85.0643\n",
      "Epoch 38/100\n",
      "404/404 [==============================] - 0s 91us/step - loss: 85.0483 - mean_squared_error: 85.0483\n",
      "Epoch 39/100\n",
      "404/404 [==============================] - 0s 90us/step - loss: 84.7863 - mean_squared_error: 84.7863\n",
      "Epoch 40/100\n",
      "404/404 [==============================] - 0s 90us/step - loss: 84.8466 - mean_squared_error: 84.8466\n",
      "Epoch 41/100\n",
      "404/404 [==============================] - 0s 94us/step - loss: 85.0581 - mean_squared_error: 85.0581\n",
      "Epoch 42/100\n",
      "404/404 [==============================] - 0s 100us/step - loss: 84.8984 - mean_squared_error: 84.8984\n",
      "Epoch 43/100\n",
      "404/404 [==============================] - 0s 87us/step - loss: 84.8381 - mean_squared_error: 84.8381\n",
      "Epoch 44/100\n",
      "404/404 [==============================] - 0s 101us/step - loss: 84.8086 - mean_squared_error: 84.8086\n",
      "Epoch 45/100\n",
      "404/404 [==============================] - 0s 98us/step - loss: 85.2746 - mean_squared_error: 85.2746\n",
      "Epoch 46/100\n",
      "404/404 [==============================] - 0s 98us/step - loss: 84.8966 - mean_squared_error: 84.8966\n",
      "Epoch 47/100\n",
      "404/404 [==============================] - 0s 99us/step - loss: 84.9494 - mean_squared_error: 84.9494\n",
      "Epoch 48/100\n",
      "404/404 [==============================] - 0s 91us/step - loss: 84.7938 - mean_squared_error: 84.7938\n",
      "Epoch 49/100\n",
      "404/404 [==============================] - ETA: 0s - loss: 79.9990 - mean_squared_error: 79.99 - 0s 100us/step - loss: 85.0213 - mean_squared_error: 85.0213\n",
      "Epoch 50/100\n",
      "404/404 [==============================] - 0s 99us/step - loss: 85.4629 - mean_squared_error: 85.4629\n",
      "Epoch 51/100\n",
      "404/404 [==============================] - 0s 106us/step - loss: 85.7233 - mean_squared_error: 85.7233\n",
      "Epoch 52/100\n",
      "404/404 [==============================] - 0s 103us/step - loss: 85.2013 - mean_squared_error: 85.2013\n",
      "Epoch 53/100\n",
      "404/404 [==============================] - 0s 98us/step - loss: 84.8155 - mean_squared_error: 84.8155\n",
      "Epoch 54/100\n",
      "404/404 [==============================] - 0s 95us/step - loss: 85.7819 - mean_squared_error: 85.7819\n",
      "Epoch 55/100\n",
      "404/404 [==============================] - 0s 95us/step - loss: 85.1112 - mean_squared_error: 85.1112\n",
      "Epoch 56/100\n",
      "404/404 [==============================] - 0s 104us/step - loss: 84.8615 - mean_squared_error: 84.8615\n",
      "Epoch 57/100\n",
      "404/404 [==============================] - 0s 102us/step - loss: 84.7935 - mean_squared_error: 84.7935\n",
      "Epoch 58/100\n",
      "404/404 [==============================] - 0s 96us/step - loss: 85.1428 - mean_squared_error: 85.1428\n",
      "Epoch 59/100\n",
      "404/404 [==============================] - 0s 99us/step - loss: 84.8904 - mean_squared_error: 84.8904\n",
      "Epoch 60/100\n",
      "404/404 [==============================] - 0s 91us/step - loss: 85.0071 - mean_squared_error: 85.0071\n",
      "Epoch 61/100\n",
      "404/404 [==============================] - 0s 93us/step - loss: 86.0859 - mean_squared_error: 86.0859\n",
      "Epoch 62/100\n",
      "404/404 [==============================] - 0s 93us/step - loss: 84.8043 - mean_squared_error: 84.8043\n",
      "Epoch 63/100\n",
      "404/404 [==============================] - 0s 98us/step - loss: 84.7919 - mean_squared_error: 84.7919\n",
      "Epoch 64/100\n",
      "404/404 [==============================] - 0s 87us/step - loss: 84.8530 - mean_squared_error: 84.8530\n",
      "Epoch 65/100\n",
      "404/404 [==============================] - 0s 97us/step - loss: 84.9229 - mean_squared_error: 84.9229\n",
      "Epoch 66/100\n",
      "404/404 [==============================] - 0s 101us/step - loss: 85.2377 - mean_squared_error: 85.2377\n",
      "Epoch 67/100\n",
      "404/404 [==============================] - 0s 98us/step - loss: 84.9232 - mean_squared_error: 84.9232\n",
      "Epoch 68/100\n",
      "404/404 [==============================] - 0s 88us/step - loss: 85.0284 - mean_squared_error: 85.0284\n",
      "Epoch 69/100\n",
      "404/404 [==============================] - 0s 95us/step - loss: 84.8985 - mean_squared_error: 84.8985\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 94us/step - loss: 85.5672 - mean_squared_error: 85.5672\n",
      "Epoch 71/100\n",
      "404/404 [==============================] - 0s 91us/step - loss: 85.0524 - mean_squared_error: 85.0524\n",
      "Epoch 72/100\n",
      "404/404 [==============================] - 0s 94us/step - loss: 84.7057 - mean_squared_error: 84.7057\n",
      "Epoch 73/100\n",
      "404/404 [==============================] - 0s 102us/step - loss: 84.9024 - mean_squared_error: 84.9024\n",
      "Epoch 74/100\n",
      "404/404 [==============================] - 0s 108us/step - loss: 84.9648 - mean_squared_error: 84.9648\n",
      "Epoch 75/100\n",
      "404/404 [==============================] - 0s 105us/step - loss: 85.2031 - mean_squared_error: 85.2031\n",
      "Epoch 76/100\n",
      "404/404 [==============================] - 0s 105us/step - loss: 84.7666 - mean_squared_error: 84.7666\n",
      "Epoch 77/100\n",
      "404/404 [==============================] - 0s 93us/step - loss: 85.0161 - mean_squared_error: 85.0161\n",
      "Epoch 78/100\n",
      "404/404 [==============================] - 0s 102us/step - loss: 84.8594 - mean_squared_error: 84.8594\n",
      "Epoch 79/100\n",
      "404/404 [==============================] - 0s 100us/step - loss: 85.0986 - mean_squared_error: 85.0986\n",
      "Epoch 80/100\n",
      "404/404 [==============================] - 0s 94us/step - loss: 84.9417 - mean_squared_error: 84.9417\n",
      "Epoch 81/100\n",
      "404/404 [==============================] - 0s 92us/step - loss: 84.9769 - mean_squared_error: 84.9769\n",
      "Epoch 82/100\n",
      "404/404 [==============================] - 0s 95us/step - loss: 85.2011 - mean_squared_error: 85.2011\n",
      "Epoch 83/100\n",
      "404/404 [==============================] - 0s 97us/step - loss: 85.0076 - mean_squared_error: 85.0076\n",
      "Epoch 84/100\n",
      "404/404 [==============================] - 0s 110us/step - loss: 84.8526 - mean_squared_error: 84.8526\n",
      "Epoch 85/100\n",
      "404/404 [==============================] - 0s 104us/step - loss: 84.9971 - mean_squared_error: 84.9971\n",
      "Epoch 86/100\n",
      "404/404 [==============================] - 0s 100us/step - loss: 86.6005 - mean_squared_error: 86.6005\n",
      "Epoch 87/100\n",
      "404/404 [==============================] - 0s 103us/step - loss: 85.5387 - mean_squared_error: 85.5387\n",
      "Epoch 88/100\n",
      "404/404 [==============================] - 0s 92us/step - loss: 85.5478 - mean_squared_error: 85.5478\n",
      "Epoch 89/100\n",
      "404/404 [==============================] - 0s 97us/step - loss: 85.0280 - mean_squared_error: 85.0280\n",
      "Epoch 90/100\n",
      "404/404 [==============================] - 0s 102us/step - loss: 84.8793 - mean_squared_error: 84.8793\n",
      "Epoch 91/100\n",
      "404/404 [==============================] - 0s 108us/step - loss: 84.9304 - mean_squared_error: 84.9304\n",
      "Epoch 92/100\n",
      "404/404 [==============================] - 0s 118us/step - loss: 85.3082 - mean_squared_error: 85.3082\n",
      "Epoch 93/100\n",
      "404/404 [==============================] - 0s 97us/step - loss: 85.0168 - mean_squared_error: 85.0168\n",
      "Epoch 94/100\n",
      "404/404 [==============================] - 0s 97us/step - loss: 84.8988 - mean_squared_error: 84.8988\n",
      "Epoch 95/100\n",
      "404/404 [==============================] - 0s 98us/step - loss: 84.8115 - mean_squared_error: 84.8115\n",
      "Epoch 96/100\n",
      "404/404 [==============================] - 0s 102us/step - loss: 84.7338 - mean_squared_error: 84.7338\n",
      "Epoch 97/100\n",
      "404/404 [==============================] - 0s 97us/step - loss: 84.8076 - mean_squared_error: 84.8076\n",
      "Epoch 98/100\n",
      "404/404 [==============================] - 0s 101us/step - loss: 84.8962 - mean_squared_error: 84.8962\n",
      "Epoch 99/100\n",
      "404/404 [==============================] - 0s 105us/step - loss: 85.2619 - mean_squared_error: 85.2619\n",
      "Epoch 100/100\n",
      "404/404 [==============================] - 0s 98us/step - loss: 84.6857 - mean_squared_error: 84.6857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7d6346f250>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 50, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation\n",
    "- Keras model can be evaluated with evaluate() function\n",
    "- Evaluation results are contained in a list\n",
    "    - Doc (metrics): https://keras.io/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 473us/step\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mean_squared_error']\n",
      "[83.48746325922947, 83.48746325922947]\n",
      "('loss: ', 83.48746325922947)\n",
      "('mse: ', 83.48746325922947)\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)     # list of metric names the model is employing\n",
    "print(results)                 # actual figure of metrics computed\n",
    "print('loss: ', results[0])\n",
    "print('mse: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP for classification tasks\n",
    "- When the target (**y**) is discrete (categorical)\n",
    "- For loss function, cross-entropy is used and for evaluation metric, accuracy is commonly used\n",
    "\n",
    "### Dataset Description\n",
    "- Breast cancer dataset has total 569 data instances (212 malign, 357 benign instances)\n",
    "- 30 attributes (features) to predict the binary class (M/B)\n",
    "- Doc: http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "whole_data = load_breast_cancer()\n",
    "\n",
    "X_data = whole_data.data\n",
    "y_data = whole_data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.3, random_state = 7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30)\n",
      "(171, 30)\n",
      "(398,)\n",
      "(171,)\n",
      "Lebels: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print('Lebels: ')\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 541\n",
      "Trainable params: 541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "model = Sequential()\n",
    "\n",
    "# Keras model with two hidden layer with 10 neurons each \n",
    "model.add(Dense(10, input_shape = (30,)))    # Input layer => input_shape should be explicitly designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))                          # Output layer => output dimension = 1 since it is regression problem\n",
    "model.add(Activation('sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compile and Training the model\n",
    "- Training the model with training data provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "398/398 [==============================] - 0s 615us/step - loss: 0.7152 - acc: 0.3945\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 0s 85us/step - loss: 0.7079 - acc: 0.3945\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - 0s 75us/step - loss: 0.7019 - acc: 0.3945\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 0s 85us/step - loss: 0.6965 - acc: 0.3945\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 0s 79us/step - loss: 0.6920 - acc: 0.5628\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 0s 78us/step - loss: 0.6884 - acc: 0.6055\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 0s 81us/step - loss: 0.6853 - acc: 0.6055\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 0s 83us/step - loss: 0.6826 - acc: 0.6055\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 0s 83us/step - loss: 0.6805 - acc: 0.6055\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 0s 90us/step - loss: 0.6787 - acc: 0.6055\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 0s 80us/step - loss: 0.6771 - acc: 0.6055\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 0s 81us/step - loss: 0.6758 - acc: 0.6055\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 0s 85us/step - loss: 0.6746 - acc: 0.6055\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 0s 83us/step - loss: 0.6738 - acc: 0.6055\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 0s 83us/step - loss: 0.6729 - acc: 0.6055\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 0s 77us/step - loss: 0.6723 - acc: 0.6055\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 0s 82us/step - loss: 0.6718 - acc: 0.6055\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 0s 84us/step - loss: 0.6712 - acc: 0.6055\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 0s 91us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 0s 77us/step - loss: 0.6704 - acc: 0.6055\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 0s 84us/step - loss: 0.6701 - acc: 0.6055\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 0s 82us/step - loss: 0.6699 - acc: 0.6055\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 0s 88us/step - loss: 0.6697 - acc: 0.6055\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 0s 81us/step - loss: 0.6695 - acc: 0.6055\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 0s 82us/step - loss: 0.6693 - acc: 0.6055\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 0s 84us/step - loss: 0.6692 - acc: 0.6055\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 0s 75us/step - loss: 0.6690 - acc: 0.6055\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 0s 85us/step - loss: 0.6689 - acc: 0.6055\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 0s 83us/step - loss: 0.6688 - acc: 0.6055\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 0s 80us/step - loss: 0.6687 - acc: 0.6055\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 0s 87us/step - loss: 0.6687 - acc: 0.6055\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 0s 85us/step - loss: 0.6686 - acc: 0.6055\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 0s 90us/step - loss: 0.6685 - acc: 0.6055\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 0s 84us/step - loss: 0.6685 - acc: 0.6055\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 0s 83us/step - loss: 0.6684 - acc: 0.6055\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 0s 79us/step - loss: 0.6685 - acc: 0.6055\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 0s 87us/step - loss: 0.6683 - acc: 0.6055\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 0s 87us/step - loss: 0.6683 - acc: 0.6055\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 0s 84us/step - loss: 0.6684 - acc: 0.6055\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 0s 95us/step - loss: 0.6682 - acc: 0.6055\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 0s 91us/step - loss: 0.6682 - acc: 0.6055\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 0s 89us/step - loss: 0.6685 - acc: 0.6055\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 0s 85us/step - loss: 0.6682 - acc: 0.6055\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 0s 88us/step - loss: 0.6681 - acc: 0.6055\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 0s 80us/step - loss: 0.6681 - acc: 0.6055\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - 0s 86us/step - loss: 0.6682 - acc: 0.6055\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 0s 84us/step - loss: 0.6682 - acc: 0.6055\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 0s 78us/step - loss: 0.6680 - acc: 0.6055\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 0s 85us/step - loss: 0.6681 - acc: 0.6055\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 0s 80us/step - loss: 0.6680 - acc: 0.6055\n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 0s 83us/step - loss: 0.6680 - acc: 0.6055\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 0s 92us/step - loss: 0.6680 - acc: 0.6055\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 0s 80us/step - loss: 0.6680 - acc: 0.6055\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 0s 78us/step - loss: 0.6679 - acc: 0.6055\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 0s 75us/step - loss: 0.6679 - acc: 0.6055\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 0s 87us/step - loss: 0.6679 - acc: 0.6055\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 0s 87us/step - loss: 0.6679 - acc: 0.6055\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 0s 94us/step - loss: 0.6678 - acc: 0.6055\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 0s 86us/step - loss: 0.6678 - acc: 0.6055\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 0s 78us/step - loss: 0.6678 - acc: 0.6055\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 0s 81us/step - loss: 0.6678 - acc: 0.6055\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 0s 83us/step - loss: 0.6678 - acc: 0.6055\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 0s 84us/step - loss: 0.6680 - acc: 0.6055\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 0s 78us/step - loss: 0.6677 - acc: 0.6055\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 0s 86us/step - loss: 0.6678 - acc: 0.6055\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - 0s 94us/step - loss: 0.6677 - acc: 0.6055\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 0s 78us/step - loss: 0.6676 - acc: 0.6055\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 0s 85us/step - loss: 0.6677 - acc: 0.6055\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 0s 90us/step - loss: 0.6677 - acc: 0.6055\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 0s 89us/step - loss: 0.6676 - acc: 0.6055\n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 0s 85us/step - loss: 0.6675 - acc: 0.6055\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 0s 82us/step - loss: 0.6676 - acc: 0.6055\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 0s 83us/step - loss: 0.6675 - acc: 0.6055\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 0s 79us/step - loss: 0.6675 - acc: 0.6055\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 0s 87us/step - loss: 0.6674 - acc: 0.6055\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 0s 87us/step - loss: 0.6674 - acc: 0.6055\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 0s 86us/step - loss: 0.6674 - acc: 0.6055\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 0s 80us/step - loss: 0.6675 - acc: 0.6055\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 0s 87us/step - loss: 0.6674 - acc: 0.6055\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 0s 82us/step - loss: 0.6673 - acc: 0.6055\n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 0s 85us/step - loss: 0.6673 - acc: 0.6055\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 0s 89us/step - loss: 0.6673 - acc: 0.6055\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 0s 88us/step - loss: 0.6673 - acc: 0.6055\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 0s 83us/step - loss: 0.6673 - acc: 0.6055\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 0s 86us/step - loss: 0.6673 - acc: 0.6055\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 0s 85us/step - loss: 0.6672 - acc: 0.6055\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 0s 79us/step - loss: 0.6672 - acc: 0.6055\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 0s 76us/step - loss: 0.6672 - acc: 0.6055\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 0s 85us/step - loss: 0.6671 - acc: 0.6055\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 0s 85us/step - loss: 0.6672 - acc: 0.6055\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 0s 89us/step - loss: 0.6672 - acc: 0.6055\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 0s 92us/step - loss: 0.6671 - acc: 0.6055\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 0s 85us/step - loss: 0.6670 - acc: 0.6055\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 0s 82us/step - loss: 0.6670 - acc: 0.6055\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 0s 81us/step - loss: 0.6671 - acc: 0.6055\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - 0s 82us/step - loss: 0.6670 - acc: 0.6055\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 0s 88us/step - loss: 0.6670 - acc: 0.6055\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 0s 83us/step - loss: 0.6670 - acc: 0.6055\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 0s 77us/step - loss: 0.6670 - acc: 0.6055\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 0s 84us/step - loss: 0.6670 - acc: 0.6055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7cd9e559d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer\n",
    "model.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size = 50, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation\n",
    "- Keras model can be evaluated with evaluate() function\n",
    "- Evaluation results are contained in a list\n",
    "    - Doc (metrics): https://keras.io/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 263us/step\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[0.6358714950712103, 0.6783625724022848]\n",
      "('loss: ', 0.6358714950712103)\n",
      "('accuracy: ', 0.6783625724022848)\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)     # list of metric names the model is employing\n",
    "print(results)                 # actual figure of metrics computed\n",
    "print('loss: ', results[0])\n",
    "print('accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's Next?\n",
    "- Implement the bigger and deeper models\n",
    "- Read training and testing samples from a diectory or files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
